<<<<<<< HEAD
arrange(desc(total)) %>%
ggplot() +
geom_col(mapping=aes(x=fct_reorder(Poll, total),y=total)) + coord_flip() + labs (x="Poll Organization", y="Total Number of Sample Voters")
edittedpoll16 %>%
filter(Poll!= "Final Results" & Poll!= "CNBCCNBC"& Poll!= "RCP Average")  %>%
group_by(Poll) %>%
select(Poll,Sample) %>%
separate((Sample), into=c("number","type")) %>%
summarise(total=sum(as.numeric(n))) %>%
arrange(desc(total)) %>%
ggplot() +
geom_col(mapping=aes(x=fct_reorder(Poll, total),y=total)) + coord_flip() + labs (x="Poll Organization", y="Total Number of Sample Voters")
edittedpoll16 %>%
filter(Poll!= "Final Results" & Poll!= "CNBCCNBC"& Poll!= "RCP Average")  %>%
group_by(Poll) %>%
select(Poll,Sample) %>%
separate((Sample), into=c("n","type")) %>%
summarise(total=sum(as.numeric(n))) %>%
arrange(desc(total)) %>%
ggplot() +
geom_col(mapping=aes(x=fct_reorder(Poll, total),y=total)) + coord_flip() + labs (x="Poll Organization", y="Total Number of Sample Voters")
edittedpoll16 %>%
filter(Poll=="NBC News/SMNBC News" | Poll=="LA Times/USC TrackingLA Times") %>%
separate((Sample), into=c("n","type")) %>%
separate((Date), into=c("start","end"), "/", convert = TRUE) %>%
gather(candidate, points, 'Clinton', 'Trump') %>%
ggplot(aes(x=points, y=end)) +
geom_point(aes(col=candidate, shape=Poll)) + labs(x="Points", y="Date")
knitr::opts_chunk$set(echo = TRUE)
library(maps)
install.packages("maps")
knitr::opts_chunk$set(echo = TRUE)
library(maps)
library(ggmap)
install.packages("ggmap")
knitr::opts_chunk$set(echo = TRUE)
library(maps)
library(ggmap)
library(tidyverse)
library(nycflights13)
data1<-flights %>%
drop_na() %>%
group_by(dest) %>%
summarise(average=mean(arr_delay)) %>%
left_join(airports, by=c("dest"="faa"))
us <- c(left = -125, bottom = 25.75, right = -67, top = 49)
map <- get_stamenmap(us, zoom = 5, maptype = "toner-lite")
ggmap(map)  # create a layer US map
ggmap(map) + geom_point(data=data1,
aes(x=lon, y=lat, color=average, size=average),na.rm = T) +
scale_color_gradient(low = "green", high="darkblue")
data2<-flights %>%
drop_na() %>%
group_by(dest) %>%
summarise(sum=n()) %>%
left_join(airports, by=c("dest"="faa"))
us <- c(left = -125, bottom = 25.75, right = -67, top = 49)
map <- get_stamenmap(us, zoom = 5, maptype = "toner-lite")
ggmap(map)
ggmap(map) + geom_point(data=data2,
aes(x=lon, y=lat, color=sum, size=sum), na.rm = T) +
scale_color_gradient(low = "blue", high="red")
ggplot(data = west_coast) +
geom_polygon(aes(x = long, y = lat), fill = "palegreen", color = "black")
west_coast <- subset(states, region %in% c("california", "oregon", "washington"))
ggplot(data = west_coast) +
geom_polygon(aes(x = long, y = lat), fill = "palegreen", color = "black")
west_coast <- subset(states, region %in% c("california", "oregon", "washington"))
states <- map_data("state")
ggplot(data = states) +
geom_polygon(aes(x = long, y = lat, fill = region, group = group), color = "white") +
coord_fixed(1.3) +
guides(fill=FALSE) # turn off the color legend
west_coast <- subset(states, region %in% c("california", "oregon", "washington"))
ggplot(data = west_coast) +
geom_polygon(aes(x = long, y = lat), fill = "palegreen", color = "black")
ggplot(data = west_coast) +
geom_polygon(aes(x = long, y = lat, group = group), fill = "palegreen", color = "black") +
coord_fixed(1.3)
library(readr)
data <- read_delim("/Users/RebeccaChao/Desktop/data.txt", "\t", escape_double = FALSE, trim_ws = TRUE)
library(dplyr)
library(tidyr)
library(ggplot2)
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
library(readr)
knitr::opts_chunk$set(echo = TRUE)
library(readr)
data <- read_delim("/Users/RebeccaChao/Desktop/data.txt", "\t", escape_double = FALSE, trim_ws = TRUE)
data <- read_delim("/Users/FarhanHossain/Desktop/data.txt", "\t", escape_double = FALSE, trim_ws = TRUE)
install.packages(c("lubridate", "purrr", "nycflights13"))
install.packages(c("lubridate", "purrr", "nycflights13"))
install.packages(c("lubridate", "purrr", "nycflights13"))
install.packages(c("lubridate", "purrr", "nycflights13"))
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(nycflights13)
library(lubridate)
library(tidyverse)
install.packages("purrr")
knitr::opts_chunk$set(echo = TRUE)
library(nycflights13)
library(lubridate)
library(tidyverse)
library(stringr)
library(purrr)
ymd("2019-01-31")
mdy("January 31st, 2019")
dmy("31-Jan-2019")
ymd_hms("2019-01-31 20:11:59")
flights %>%
select(year, month, day, hour, minute) %>%
mutate(departure_sched = make_datetime(year, month, day, hour, minute))
make_datetime_100 <- function(year, month, day, time) {
make_datetime(year, month, day, time %/% 100, time %% 100)
}
flights_dt <- flights %>%
filter(!is.na(dep_time), !is.na(arr_time)) %>%
mutate(
dep_time = make_datetime_100(year, month, day, dep_time),
arr_time = make_datetime_100(year, month, day, arr_time),
sched_dep_time = make_datetime_100(year, month, day, sched_dep_time),
sched_arr_time = make_datetime_100(year, month, day, sched_arr_time)
) %>%
select(origin, dest, ends_with("delay"), ends_with("time"))
knitr::opts_chunk$set(echo = TRUE)
library(nycflights13)
library(lubridate)
library(tidyverse)
library(stringr)
set.seed(1000)
exams <- list(
student1 = round(runif(10, 50, 100)),
student2 = round(runif(10, 50, 100)),
student3 = round(runif(10, 50, 100)),
student4 = round(runif(10, 50, 100)),
student5 = round(runif(10, 50, 100))
)
library(purrr)
grade<-function(x) {(sum(x) + max(x))/11}
map(exams, grade)
average<- function(x) {
x[x < 60] <- 60
x
mean(x)
}
map(exams, average)
linearmodel<- mtcars %>%
split(.$cyl) %>%
map(function(df) lm(mpg ~ wt, data = df))
linearmodel
library(maps)
library(ggmap)
flu<- read.csv("flu.csv")
flu<- read.csv("flu.csv")
flu<- read.csv ("flu.csv")
knitr::opts_chunk$set(echo = TRUE)
library(nycflights13)
library(lubridate)
library(tidyverse)
library(stringr)
set.seed(1000)
exams <- list(
student1 = round(runif(10, 50, 100)),
student2 = round(runif(10, 50, 100)),
student3 = round(runif(10, 50, 100)),
student4 = round(runif(10, 50, 100)),
student5 = round(runif(10, 50, 100))
)
library(purrr)
grade<-function(x) {(sum(x) + max(x))/11}
map(exams, grade)
library(purrr)
grade<-function(x) {(sum(x) + max(x))/11}
map(exams, grade)
set.seed(1000)
exams <- list(
student1 = round(runif(10, 50, 100)),
student2 = round(runif(10, 50, 100)),
student3 = round(runif(10, 50, 100)),
student4 = round(runif(10, 50, 100)),
student5 = round(runif(10, 50, 100))
)
library(purrr)
grade <-function(x) {(sum(x) + max(x))/11}
map(exams, grade)
knitr::opts_chunk$set(echo = TRUE)
set.seed(1000)
exams <- list(
student1 = round(runif(10, 50, 100)),
student2 = round(runif(10, 50, 100)),
student3 = round(runif(10, 50, 100)),
student4 = round(runif(10, 50, 100)),
student5 = round(runif(10, 50, 100))
)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(nycflights13)
library(lubridate)
library(stringr)
library(purrr)
set.seed(1000)
exams <- list(
student1 = round(runif(10, 50, 100)),
student2 = round(runif(10, 50, 100)),
student3 = round(runif(10, 50, 100)),
student4 = round(runif(10, 50, 100)),
student5 = round(runif(10, 50, 100))
)
besty <- exams %>%
map(max)
install.packages("sqldf")
knitr::opts_chunk$set(echo = TRUE)
data1<-data %>%
left_join(dest) %>%
group_by(srch_destination_name) %>%
summarise(sum=sum(srch_children_cnt))
knitr::opts_chunk$set(echo = TRUE)
data1<-travel %>%
group_by(srch_children_cnt) %>%
summarise(sum=n()) %>%
left_join(dest, by=c("srch_children_cnt"="srch_destination_id"))
library(dplyr)
library(tidyr)
library(ggplot2)
library(tidyverse)
library(maps)
library(ggmap)
data1<-travel %>%
group_by(srch_children_cnt) %>%
summarise(sum=n()) %>%
left_join(dest, by=c("srch_children_cnt"="srch_destination_id"))
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(ggplot2)
library(tidyverse)
library(maps)
library(ggmap)
data1 <- data %>%
left_join(dest) %>%
filter(srch_destination_latitude != 'NULL')%>%
group_by(srch_destination_name) %>%
mutate(sum=sum(srch_children_cnt))
data <- <- read.csv(file="data.csv", header=TRUE, sep=",")
data <- read.csv(file="data.csv", header=TRUE, sep=",")
dest <- read.csv(file="dest.csv", header=TRUE, sep=",")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(ggplot2)
library(tidyverse)
library(maps)
library(ggmap)
data <- read.csv(file="data.csv", header=TRUE, sep=",")
dest <- read.csv(file="dest.csv", header=TRUE, sep=",")
data1 <- data %>%
left_join(dest) %>%
filter(srch_destination_latitude != 'NULL')%>%
group_by(srch_destination_name) %>%
mutate(sum=sum(srch_children_cnt))
# create the base layer of the US map
us <- c(left = -125, bottom = 25.75, right = -67, top = 49)
map <- get_stamenmap(us, zoom = 5, maptype = "toner-lite")
# add data points to the map
ggmap(map) + geom_point(data=data1,
aes(x=as.numeric(as.character(srch_destination_longitude)), y=as.numeric(as.character(srch_destination_latitude)), color=sum, size=sum),na.rm=T) +
scale_color_gradient(low = "green", high="darkblue")
data2 <- data1 %>%
filter(sum < 4000)
ggmap(map) + geom_point(data=data2,
aes(x=as.numeric(as.character(srch_destination_longitude)), y=as.numeric(as.character(srch_destination_latitude)), color=sum, size=sum),na.rm=T) +
scale_color_gradient(low = "green", high="darkblue")
monthdata <- data %>%
separate(date_time, into = c("month", "date"), sep="/") %>%
group_by(month) %>%
mutate(sum=sum(srch_children_cnt))
ggplot(monthdata, aes(x=fct_reorder(month, sum), y=sum)) + geom_point() +
labs(x="Month", y="Total Children", title="Popular Travel Months for Children")
packagedata <- data %>%
separate(date_time, into = c("month", "date"), sep="/") %>%
group_by(month) %>%
mutate(sum=sum(is_package))
ggplot(packagedata, aes(x=fct_reorder(month, sum), y=sum)) + geom_point() +
labs(x="Month", y="Total Package Searches", title="Popular Months for Packages")
=======
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
## Calculate the mean, standard deviation, and sample size in order to calculate the lower and upper bounds of the confidence interval.
meanIQ <- sum(y)/length(y)
demeanedSum <- NULL
for(i in 1:length(y)){
demeanedSum[i] <- y[i] - meanIQ
}
squaredError <- demeanedSum^2
variance <- sum(squaredError)/(length(y) - 1)
sdIQ <- sqrt(variance)
z90 <- qt((1-.9)/2, 24)
lower_90 <- meanIQ + z90*sdIQ/sqrt(length(y))
upper_90 <- meanIQ - z90*sdIQ/sqrt(length(y))
confint90 <- c(lower_90, upper_90)
confint90
t.test(y, conf.level = 0.9)
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
#confidence coefficient is 0.90
#using qtnorm because n is <30
library(msm)
lapply(c("msm"),  pkgTest)
# remove objects
>>>>>>> upstream/master
rm(list=ls())
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
<<<<<<< HEAD
lapply(c(),  pkgTest)
setwd("~/Documents/GitHub/QTM200Spring2020/problem_sets/PS1")
setwd("~/Documents/Emory 3rd Year/QTM 200/QTM200Spring2020/problem_sets/PS1")
setwd("~/Documents/Emory 3rd Year/QTM 200/QTM200Spring2020/problem_sets/PS1")
setwd("~/Documents/'Emory 3rd Year'/'QTM 200'/QTM200Spring2020/problem_sets/PS1")
setwd("~/Emory 3rd Year/QTM 200/QTM200Spring2020/problem_sets/PS1")
setwd("~/Emory 3rd Year/QTM 200/QTM200Spring2020/problem_sets/PS1")
z90 <- qt((1-.90)/2, lower.tail = FALSE)
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
z90 <- qt((1 - .90)/2, lower.tail = FALSE)
z90 <- qnorm((1 - .90)/2, lower.tail = FALSE)
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
z90 <- qnorm((1 - .90)/2, lower.tail = FALSE)
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
z90 <- qt((1 - .90)/2, lower.tail = FALSE)
n
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
z90 <- qt((1 - .90)/2, lower.tail = FALSE)
z90 <- qnorm((1 - .90)/2, lower.tail = FALSE)
n <- length(y)
sample_mean
sample_mean <- mean(y)
sample_sd <- sd(y)
lower_90 <- sample_mean - (z90 * (sample_sd/sqrt(n)))
upper_90 <- sample_mean + (z90 * (sample_sd/sqrt(n)))
confint90 <- c(lower_90, upper_90)
confint90
sample_mean
n
sample_sd
sample_mean
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
sample_mean
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
sample_mean <- mean(y)
sample_mean
mu <- 100
sample_mean <- mean(y)
sample_sd <- sd(y)
n <- length(y)
teststatistic <- ((sample_mean-mu)/(sample_sd/sqrt(n))
teststatistic
mu <- 100
n <- length(y)
sample_mean <- mean(y)
sample_sd <- sd(y)
teststatistic <- ((sample_mean-mu)/(sample_sd/sqrt(n))
y <- c(1, 2, 1, 3, 4, 1, 1, 4, 2, 1, 3, 4, 3, 2, 1, 3, 4, 1, 2, 3, 1, 1, 2, 1, 1, 3, 4)
teststatistic <- (sample_mean-mu)/(sample_sd/sqrt(n))
teststatistic
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
t.test(y, mu = 100,
alternative = "greater")
teststatistic
pt(abs(teststatistic), df = n - 1)
y <- c(1, 2, 1, 3, 4, 1, 1, 4, 2, 1, 3, 4, 3, 2, 1, 3, 4, 1, 2, 3, 1, 1, 2, 1, 1, 3, 4)
expenditure <- read.table("expenditure.txt", header=T)
y.factor <- factor(y)
y.factor
class <- c("Freshman", "Sophomore", "Junior", "Senior")
y.factor <- factor(class)
y.factor
as.character(y)
as.character(y.factor)
y.factor <- factor(class)
as.character(y.factor)
y.character <- factor(y, levels = c("Freshman", "Sophomore", "Junior", "Senior"))
y <- c(1, 2, 1, 3, 4, 1, 1, 4, 2, 1, 3, 4, 3, 2, 1, 3, 4, 1, 2, 3, 1, 1, 2, 1, 1, 3, 4)
y.character <- factor(y, levels = c("Freshman", "Sophomore", "Junior", "Senior"))
as.numeric(y)
as.character(y)
y.character <- c("Freshman", "Sophomore", "Junior", "Senior")[y]
y.character
y <- c(1, 2, 1, 3, 4, 1, 1, 4, 2, 1, 3, 4, 3, 2, 1, 3, 4, 1, 2, 3, 1, 1, 2, 1, 1, 3, 4)
y.characters <- c("Freshman", "Sophomore", "Junior", "Senior")[y]
y.characters
y.characters <- c("Freshman", "Sophomore", "Junior", "Senior")
y <- c(1, 2, 1, 3, 4, 1, 1, 4, 2, 1, 3, 4, 3, 2, 1, 3, 4, 1, 2, 3, 1, 1, 2, 1, 1, 3, 4)
y.characters <- c("Freshman", "Sophomore", "Junior", "Senior")
y.characters
y.characters <- c("Freshman", "Sophomore", "Junior", "Senior")[y]
y.characters
expenditure <- read.table("expenditure.txt", header=T)
head(expenditure,6)
res <- cor(expenditure)
round(res,2)
cor(expenditure$Y, expenditure$X1, expenditure$X2, expenditure$X3)
cor(expenditure$Y, expenditure$X1)
round(cor(expenditure),2)
exp_data <- expenditure[,2:length(expenditure)]
round(cor(exp_data),2)
plot(expenditure$Y, expenditure$X1)
plot(expenditure$X1, expenditure$Y)
plot(expenditure$Y, expenditure$X1)
plot(expenditure$X1, expenditure$Y)
plot(expenditure$X1, expenditure$Y)
plot(expenditure$Y, expenditure$X1)
plot(expenditure$X1, expenditure$Y)
plot(expenditure$X1, expenditure$Y)
plot(expenditure$X2, expenditure$Y)
plot(expenditure$X3, expenditure$Y)
plot(expenditure$X1, expenditure$Y)
plot(expenditure$X1, expenditure$Y)
plot(expenditure$X2, expenditure$Y)
plot(expenditure$X3, expenditure$Y)
plot(expenditure$X1, expenditure$X2)
plot(expenditure$X1, expenditure$X3)
plot(expenditure$Region, expenditure$Y)
head(expenditure,6)
# we fail to reject the null
#####################
# Problem 3
#####################
library(dplyr)
install.packages("dplyr")
# we fail to reject the null
#####################
# Problem 3
#####################
library(dplyr)
# we fail to reject the null
#####################
# Problem 3
#####################
library(dplyr)
region1 <- filter(expenditure, expenditure$Region == 1)
region1
mean(region1)
mean(region1$Y)
region2 <- filter(expenditure, expenditure$Region == 2)
mean(region2$Y)
region3 <- filter(expenditure, expenditure$Region == 3)
mean(region3$Y)
region4 <- filter(expenditure, expenditure$Region == 4)
mean(region4$Y)
plot(expenditure$Y, expenditure$X1)
plot(expenditure$Y, expenditure$X1, expenditure$Region)
plot(expenditure$Y ~ expenditure$X1, pch=as.integer(expenditure$Region)
plot(expenditure$Y ~ expenditure$X1, pch=as.integer(expenditure$Region))
attach(expenditure)
plot(expenditure$Y ~ expenditure$X1, pch=as.integer(expenditure$Region))
plot(expenditure$Y ~ expenditure$X1, pch=as.integer(expenditure$Region), col=as.integer(expenditure$Region))
legend(650, 2, c("Region 1", "Region 2", "REgion 3", "Region 4"), pch=1, col=c(1,2,3))
plot(expenditure$Y ~ expenditure$X1, pch=as.integer(expenditure$Region), col=as.integer(expenditure$Region))
legend(650, 2, c("Region 1", "Region 2", "REgion 3", "Region 4"), pch=1, col=c(1,2,3))
plot(expenditure$Y ~ expenditure$X1, pch=as.integer(expenditure$Region), col=as.integer(expenditure$Region))
legend(650, 2, c("Region 1", "Region 2", "REgion 3", "Region 4"), pch=1, col=c(1,2,3))
legend(650, 2, c("Region 1", "Region 2", "REgion 3", "Region 4"), pch=1, col=c(1,2,3))
plot(expenditure$Y ~ expenditure$X1, pch=as.integer(expenditure$Region), col=as.integer(expenditure$Region))
plot(expenditure$X1 ~ expenditure$Y, pch=as.integer(expenditure$Region), col=as.integer(expenditure$Region))
Y
plot(expenditure$Y ~ expenditure$X1, pch=as.integer(expenditure$Region), col=as.integer(expenditure$Region))
plot(expenditure$X1, expenditure$Y)
plot(expenditure$Y ~ expenditure$X1, pch=as.integer(expenditure$Region), col=as.integer(expenditure$Region))
confint90
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
n <- length(y)
sample_mean <- mean(y)
sample_sd <- sd(y)
lower_90 <- sample_mean - (z90 * (sample_sd/sqrt(n)))
upper_90 <- sample_mean + (z90 * (sample_sd/sqrt(n)))
confint90 <- c(lower_90, upper_90)
z90 <- qnorm((1 - .90)/2, lower.tail = FALSE)
confint90
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
t.test(y, mu = 100,
alternative = "greater")
# OR
mu <- 100
n <- length(y)
sample_mean <- mean(y)
sample_sd <- sd(y)
teststatistic <- (sample_mean-mu)/(sample_sd/sqrt(n))
teststatistic
pt(abs(teststatistic), df = n - 1)
expenditure <- read.table("expenditure.txt", header=T)
head(expenditure,6)
cor(expenditure$Y, expenditure$X1)
exp_data <- expenditure[,2:length(expenditure)]
round(cor(exp_data),2)
expenditure <- read.table("expenditure.txt", header=T)
head(expenditure,6)
cor(expenditure$Y, expenditure$X1)
exp_data <- expenditure[,2:length(expenditure)]
round(cor(exp_data),2)
plot(expenditure$X1, expenditure$Y)
plot(expenditure$X1, expenditure$Y)
plot(expenditure$X2, expenditure$Y)
plot(expenditure$X3, expenditure$Y)
plot(expenditure$X1, expenditure$X2)
plot(expenditure$X1, expenditure$X3)
plot(expenditure$X1, expenditure$X3)
plot(expenditure$X2, expenditure$X3)
plot(expenditure$X3, expenditure$Y)
plot(expenditure$X2, expenditure$X3)
region1 <- filter(expenditure, expenditure$Region == 1)
mean(region1$Y)
region2 <- filter(expenditure, expenditure$Region == 2)
mean(region2$Y)
region3 <- filter(expenditure, expenditure$Region == 3)
mean(region3$Y)
region4 <- filter(expenditure, expenditure$Region == 4)
mean(region4$Y)
attach(expenditure)
expenditure <- read.table("expenditure.txt", header=T)
attach(expenditure)
plot(expenditure$Y ~ expenditure$X1, pch=as.integer(expenditure$Region), col=as.integer(expenditure$Region))
expenditure <- read.table("expenditure.txt", header=T)
head(expenditure,6)
cor(expenditure$Y, expenditure$X1)
exp_data <- expenditure[,2:length(expenditure)]
round(cor(exp_data),2)
=======
# here is where you load any necessary packages
# ex: stringr
# lapply(c("stringr"),  pkgTest)
lapply(c("msm"),  pkgTest)
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
z90 <- qtnorm((1-0.90)/2, lower.tail = FALSE)
n <- length(y)
sample_mean <- mean(y)
sample_sd <- sd(y)
lower_90 <- sample_mean - (z90 * (sample_sd/sqrt(n)))
upper_90 <- sample_mean + (z90 * (sample_sd/sqrt(n)))
confint90 <- c(lower_90, upper_90)
confint90
?qtnorm
#Taking Data set and pasting
problem_1 <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
mean(problem_1) #the sample mean for IQ score is 98.44
length(problem_1) # three are 25 observations by counselor on student IQ scores
sd(problem_1) # the standard deviation of the observations in IQ scores is 13.09
std_error <- sd(problem_1) / sqrt(length(problem_1)) #accounting standard deviation based on our sample size to obtain sample error
std_error # standard error is 2.62
sqrt(10)
qt(0.05,n−1,lower.tail=F)
qt(0.05,25−1,lower.tail=F)
qt(0.05,24,lower.tail=F)
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
#calculate a test statistic
mean(y) #sample mean = 98.44
#population mean = 100
sd(y) #sd of sample = 13.09
13.09/sqrt(25) #standard deviation of sampling distribution = 2.618
(98.44-100)/2.618 #-0.5958747, df=24
SE<−sd(y)/sqrt(n)
# Step 2: Calculate the test statistic for this hypothesis testing of mean
t <− (mean(y) − 100)/SE
SE<-sd(y)/sqrt(n)
# Step 2: Calculate the test statistic for this hypothesis testing of mean
t <- (mean(y) -100)/SE
t
expenditure <- read.table("expenditure.txt", header=T)
# set working directory
setwd("~/GitHub/QTM200Spring2020/problem_sets/PS1")
# set working directory
setwd("~/Documents/GitHub/QTM200Spring2020/problem_sets/PS1")
expenditure <- read.table("expenditure.txt", header=T)
#Please plot the reltionships among Y, X1, X2, and X3.
#Plot Y
expenditure$Y
hist(expenditure$Y, main="Per Capita Expenditure on Public Education", xlab="Y", ylab="Frequency")
#Plot X1
hist(expenditure$X1, main="Per Capita Personal Income", xlab="X1", ylab="Frequency")
#Plot X2
hist(expenditure$X2, main="Number of Residents per Thousand Under 18 Years", xlab="X2", ylab="Frequency")
#Reproduce the above graph adding region and display different regions with different colors/symbols.
plot(expenditure$Y, expenditure$X1, col=as.integer(expenditure$Region), pch=as.integer(expenditure$Region), main = "Public Education Expenditure & Personal Income Per Capita by Region", xlab="Y", ylab="X1")
>>>>>>> upstream/master
